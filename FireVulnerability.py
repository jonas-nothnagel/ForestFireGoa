#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
FireVulnerability.py: Python implementation of FireVulnerability.js using Earth Engine Python API.
This script creates fire vulnerability maps for the study area in Goa, India.

The script performs the following steps:
1. Loads fire event data from multiple years
2. Generates random points for non-fire locations
3. Extracts predictor variables at fire and non-fire locations
4. Categorizes fire locations by risk level based on surrounding conditions
5. Trains a Random Forest classifier to predict fire vulnerability
6. Validates the model with independent test data
7. Generates a fire vulnerability map for the entire study area
8. Exports the vulnerability map to Google Drive and/or Earth Engine assets

Equivalent to the FireVulnerability.js script in the original implementation.
"""

import ee
import os
import datetime
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import geopandas as gpd
from tqdm import tqdm
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import seaborn as sns

# Initialize the Earth Engine API
try:
    ee.Initialize()
    print("Earth Engine API initialized successfully.")
except Exception as e:
    print(f"Error initializing Earth Engine API: {e}")
    print("Make sure you have authenticated with Earth Engine using ee.Authenticate()")

# Define the Goa study area boundary
def get_study_boundary():
    """
    Get the study area boundary for Goa, India.
    Returns an ee.Geometry.
    """
    # Method 1: Load from a shapefile if available locally
    try:
        boundary_path = os.path.join('data', 'pa_boundary.shp')
        if os.path.exists(boundary_path):
            boundary_gdf = gpd.read_file(boundary_path)
            # Convert to GeoJSON
            boundary_geojson = boundary_gdf.geometry.__geo_interface__
            # Create an EE geometry
            return ee.Geometry.Polygon(boundary_geojson['features'][0]['geometry']['coordinates'])
    except Exception as e:
        print(f"Could not load boundary from shapefile: {e}")
    
    # Method 2: Use predefined feature from Earth Engine
    try:
        # Get the Goa district boundary from Earth Engine's administrative boundaries
        goa = ee.FeatureCollection("FAO/GAUL/2015/level1").filter(ee.Filter.eq('ADM1_NAME', 'Goa'))
        return goa.geometry()
    except Exception as e:
        print(f"Could not load boundary from Earth Engine: {e}")
        
    # Method 3: Define manually as fallback
    # These coordinates would need to be adjusted to match the study area
    goa_coords = [
        [73.6765, 15.7560],
        [74.3161, 15.7560],
        [74.3161, 14.8922],
        [73.6765, 14.8922],
        [73.6765, 15.7560]
    ]
    return ee.Geometry.Polygon(goa_coords)

# Function to load fire events data
def load_fire_events(pa):
    """
    Load fire events data from 2013-2023 and merge into a single feature collection.
    
    Args:
        pa: ee.Geometry representing the study area
    
    Returns:
        ee.FeatureCollection of fire events
    """
    print("Loading fire events data...")
    
    # Load fire events data (2013-2019)
    try:
        # If the data is available in Earth Engine, you can load it directly
        fire_13_19 = ee.FeatureCollection("users/your_username/fire13_19")
    except:
        # Otherwise, try to find and upload it, or use a placeholder
        print("Fire data 2013-2019 not available in Earth Engine. Using placeholder.")
        fire_13_19 = ee.FeatureCollection([])
    
    # Load fire events data (2020-2023)
    try:
        # If the data is available in Earth Engine, you can load it directly
        fire_20_23 = ee.FeatureCollection("users/your_username/fire20_23")
    except:
        # Otherwise, try to find and upload it, or use a placeholder
        print("Fire data 2020-2023 not available in Earth Engine. Using placeholder.")
        fire_20_23 = ee.FeatureCollection([])
    
    # Merge the two collections
    fire_all = fire_13_19.merge(fire_20_23)
    
    # Filter by the study area boundary
    fire_all = fire_all.filterBounds(pa)
    
    # Add a 'year' property based on the acquisition date
    def add_year(feature):
        acq_date = ee.String(feature.get('ACQ_DATE'))
        year = ee.Number.parse(acq_date.slice(0, 4))
        return feature.set('year', year)
    
    fire_all = fire_all.map(add_year)
    
    # Filter to include only 2013-2022 for training (2023 will be used for validation)
    fire_training = fire_all.filter(ee.Filter.lt('year', 2023))
    
    # Count the number of fire points
    training_count = fire_training.size().getInfo()
    print(f"Number of fire events for training (2013-2022): {training_count}")
    
    # Get 2023 fire events for validation
    fire_validation = fire_all.filter(ee.Filter.eq('year', 2023))
    validation_count = fire_validation.size().getInfo()
    print(f"Number of fire events for validation (2023): {validation_count}")
    
    return fire_all, fire_training, fire_validation

# Function to load road data
def load_roads(pa):
    """
    Load roads data and clip to the study area.
    
    Args:
        pa: ee.Geometry representing the study area
    
    Returns:
        ee.Image with roads data
    """
    print("Loading roads data...")
    
    try:
        # Try to load the road data from Earth Engine assets
        roads = ee.Image("users/your_username/road").clip(pa)
        return roads
    except:
        print("Road data not available in Earth Engine. Using OSM roads as fallback.")
        # Use OpenStreetMap data as a fallback
        roads = ee.FeatureCollection('OSM/2020/roads').filterBounds(pa)
        
        # Convert to an image
        roads_image = roads.reduceToImage(
            properties=['highway'],
            reducer=ee.Reducer.first()
        ).clip(pa)
        
        return roads_image

# Function to generate random non-fire points
def generate_non_fire_points(pa, fire_training, num_points=100, buffer_distance=500):
    """
    Generate random points for non-fire locations within the study area.
    
    Args:
        pa: ee.Geometry representing the study area
        fire_training: ee.FeatureCollection of fire points
        num_points: Number of random points to generate
        buffer_distance: Buffer distance (in meters) to avoid fire locations
    
    Returns:
        ee.FeatureCollection of non-fire points
    """
    print(f"Generating {num_points} random non-fire points...")
    
    # Create a buffer around fire points to avoid
    fire_buffer = fire_training.geometry().buffer(buffer_distance)
    
    # Create a mask to avoid sampling in fire buffer zones
    mask = ee.Image(1).clip(pa).updateMask(
        ee.Image(1).clip(pa).mask().subtract(
            ee.Image(1).clip(fire_buffer).mask()
        )
    )
    
    # Generate random points in the valid sampling area
    non_fire_points = ee.FeatureCollection.randomPoints({
        'region': pa,
        'points': num_points,
        'seed': 42,
        'mask': mask
    })
    
    # Add a risk property (0 for non-fire)
    non_fire_points = non_fire_points.map(lambda f: f.set('RiskNumeric', 0))
    
    # Check if we have enough points
    point_count = non_fire_points.size().getInfo()
    print(f"Generated {point_count} non-fire points")
    
    return non_fire_points

# Function to calculate Land Surface Temperature trends from MODIS data
def calculate_lst_trends(pa, start_date='2013-01-01', end_date='2022-12-31'):
    """
    Calculate Land Surface Temperature (LST) trends from MODIS data.
    
    Args:
        pa: ee.Geometry representing the study area
        start_date: Start date for trend calculation
        end_date: End date for trend calculation
    
    Returns:
        ee.Image with LST trend bands
    """
    print("Calculating Land Surface Temperature trends...")
    
    # Function to mask clouds in MODIS LST imagery
    def maskLstClouds(image):
        qc = image.select('QC_Day')
        # Bit 0-1: LST produced, good quality
        mask = qc.bitwiseAnd(3).eq(0)
        return image.updateMask(mask)
    
    # Load the MODIS LST data
    modis_lst = ee.ImageCollection('MODIS/061/MOD11A1') \
        .filterDate(start_date, end_date) \
        .filterBounds(pa)
    
    # Apply cloud masking
    modis_lst_masked = modis_lst.map(maskLstClouds)
    
    # Convert LST to Celsius
    modis_lst_celsius = modis_lst_masked.map(
        lambda image: image.select(['LST_Day_1km', 'LST_Night_1km'])
                          .multiply(0.02)
                          .subtract(273.15)
                          .copyProperties(image, ['system:time_start'])
    )
    
    # Function to add time band for trend calculation
    def addTime(image):
        # Get the timestamp and convert to years since start
        year = ee.Date(image.get('system:time_start')).difference(
            ee.Date(start_date), 'year')
        return image.addBands(ee.Image(year).rename('t'))
    
    # Add time band to the collection
    modis_lst_with_time = modis_lst_celsius.map(addTime)
    
    # Calculate trends for day and night LST
    day_trend = modis_lst_with_time.select(['t', 'LST_Day_1km']) \
        .reduce(ee.Reducer.linearFit()) \
        .select(['scale'], ['lst_day_trend'])
    
    night_trend = modis_lst_with_time.select(['t', 'LST_Night_1km']) \
        .reduce(ee.Reducer.linearFit()) \
        .select(['scale'], ['lst_night_trend'])
    
    # Calculate delta LST (day-night)
    def calculateDeltaLST(image):
        day = image.select('LST_Day_1km')
        night = image.select('LST_Night_1km')
        delta = day.subtract(night).rename('delta_lst')
        return image.addBands(delta)
    
    modis_lst_with_delta = modis_lst_celsius.map(calculateDeltaLST)
    
    # Calculate delta LST trend
    delta_trend = modis_lst_with_delta.map(addTime) \
        .select(['t', 'delta_lst']) \
        .reduce(ee.Reducer.linearFit()) \
        .select(['scale'], ['delta_lst_trend'])
    
    # Merge all LST trend layers
    lst_trends = day_trend.addBands(night_trend).addBands(delta_trend)
    
    return lst_trends.clip(pa)

# Function to load trend layers from TrendFire output
def load_trend_layers(pa):
    """
    Load trend layers previously calculated using TrendFire.py.
    
    Args:
        pa: ee.Geometry representing the study area
    
    Returns:
        ee.Image with all trend bands
    """
    print("Loading trend layers...")
    
    try:
        # Try to load the trend layers from Earth Engine assets
        trends = ee.Image("users/your_username/goa_fire_trends").clip(pa)
        print("Successfully loaded trend layers from Earth Engine asset.")
        return trends
    except:
        print("Trend layers not found in Earth Engine assets. Calculating LST trends as fallback.")
        # Calculate LST trends as a fallback
        lst_trends = calculate_lst_trends(pa)
        return lst_trends

# Function to categorize fire risk based on temperature difference
def categorize_fire_risk(fire_training, lst_data, pa):
    """
    Categorize fire points by risk level based on temperature difference.
    
    Args:
        fire_training: ee.FeatureCollection of fire points
        lst_data: ee.Image with LST data
        pa: ee.Geometry representing the study area
    
    Returns:
        ee.FeatureCollection of categorized fire points
    """
    print("Categorizing fire risk levels...")
    
    # Sample the delta LST values at fire locations
    fire_samples = lst_data.select('delta_lst_trend').sampleRegions({
        'collection': fire_training,
        'properties': ['ACQ_DATE', 'year'],
        'scale': 1000,  # MODIS LST resolution
        'geometries': True
    })
    
    # Define threshold values for risk categories
    # These thresholds would need to be calibrated based on local conditions
    def categorize(feature):
        delta_lst = feature.get('delta_lst_trend')
        
        # Define risk categories based on delta LST
        # 1: Low risk, 2: Moderate risk, 3: High risk
        risk = ee.Algorithms.If(ee.Number(delta_lst).lt(0.1), 1,
               ee.Algorithms.If(ee.Number(delta_lst).lt(0.2), 2, 3))
        
        return feature.set('RiskNumeric', risk)
    
    # Apply categorization to all fire points
    categorized_fire = fire_samples.map(categorize)
    
    # Count points in each risk category
    low_risk = categorized_fire.filter(ee.Filter.eq('RiskNumeric', 1)).size().getInfo()
    moderate_risk = categorized_fire.filter(ee.Filter.eq('RiskNumeric', 2)).size().getInfo()
    high_risk = categorized_fire.filter(ee.Filter.eq('RiskNumeric', 3)).size().getInfo()
    
    print(f"Fire risk categorization: {low_risk} Low, {moderate_risk} Moderate, {high_risk} High risk")
    
    return categorized_fire

# Function to prepare training data
def prepare_training_data(categorized_fire, non_fire_points, trend_layers, roads, pa):
    """
    Prepare training data for the Random Forest classifier.
    
    Args:
        categorized_fire: ee.FeatureCollection of fire points with risk levels
        non_fire_points: ee.FeatureCollection of non-fire points
        trend_layers: ee.Image with trend bands
        roads: ee.Image with road data
        pa: ee.Geometry representing the study area
    
    Returns:
        ee.FeatureCollection with training data
    """
    print("Preparing training data for Random Forest classifier...")
    
    # Combine fire and non-fire points
    training_points = categorized_fire.merge(non_fire_points)
    
    # Calculate distance to roads
    road_distance = roads.fastDistanceTransform(100).multiply(30).clip(pa)
    
    # Combine all predictor variables
    predictor_variables = trend_layers.addBands(road_distance.rename('road_distance'))
    
    # Sample the predictor variables at training points
    training_data = predictor_variables.sampleRegions({
        'collection': training_points,
        'properties': ['RiskNumeric'],
        'scale': 30,
        'geometries': True
    })
    
    # Count the final number of training points
    training_count = training_data.size().getInfo()
    print(f"Final training dataset contains {training_count} points")
    
    return training_data

# Function to train a Random Forest classifier
def train_random_forest(training_data, num_trees=500):
    """
    Train a Random Forest classifier using Earth Engine.
    
    Args:
        training_data: ee.FeatureCollection with training data
        num_trees: Number of trees in the Random Forest
    
    Returns:
        ee.Classifier.RandomForest
    """
    print(f"Training Random Forest classifier with {num_trees} trees...")
    
    # Get the names of the predictor bands
    predictor_names = training_data.first().propertyNames().removeAll(['system:index', 'RiskNumeric']).getInfo()
    
    # Create and train the classifier
    classifier = ee.Classifier.smileRandomForest(
        numberOfTrees=num_trees, 
        minLeafPopulation=1,
        bagFraction=0.7,
        seed=42
    ).train(
        features=training_data,
        classProperty='RiskNumeric',
        inputProperties=predictor_names
    )
    
    # Print variable importance
    variable_importance = classifier.explain().get('importance').getInfo()
    print("Variable importance:")
    for var, importance in zip(predictor_names, variable_importance):
        print(f"  {var}: {importance:.4f}")
    
    return classifier, predictor_names

# Function to validate the Random Forest model
def validate_model(classifier, predictor_names, validation_data):
    """
    Validate the Random Forest model using test data.
    
    Args:
        classifier: Trained ee.Classifier.RandomForest
        predictor_names: List of predictor variable names
        validation_data: ee.FeatureCollection with validation data
    
    Returns:
        Dictionary with validation metrics
    """
    print("Validating Random Forest model...")
    
    # Apply the classifier to the validation data
    validated = validation_data.classify(classifier)
    
    # Get the confusion matrix
    confusion_matrix = validated.errorMatrix('RiskNumeric', 'classification')
    
    # Calculate accuracy and Kappa statistics
    accuracy = confusion_matrix.accuracy().getInfo()
    kappa = confusion_matrix.kappa().getInfo()
    
    print(f"Validation accuracy: {accuracy:.4f}")
    print(f"Kappa statistic: {kappa:.4f}")
    
    # Get confusion matrix as a list of lists
    cm_data = confusion_matrix.getInfo()
    
    # Return validation metrics
    return {
        'accuracy': accuracy,
        'kappa': kappa,
        'confusion_matrix': cm_data
    }

# Function to create a fire vulnerability map
def create_vulnerability_map(classifier, predictor_variables, predictor_names, pa):
    """
    Create a fire vulnerability map using the trained classifier.
    
    Args:
        classifier: Trained ee.Classifier.RandomForest
        predictor_variables: ee.Image with predictor variables
        predictor_names: List of predictor variable names
        pa: ee.Geometry representing the study area
    
    Returns:
        ee.Image with fire vulnerability classification
    """
    print("Creating fire vulnerability map...")
    
    # Select only the predictor bands used for training
    predictors = predictor_variables.select(predictor_names)
    
    # Apply the classifier to create a vulnerability map
    vulnerability_map = predictors.classify(classifier).clip(pa)
    
    return vulnerability_map

# Function to export the vulnerability map to Google Drive
def export_vulnerability_map(vulnerability_map, pa, filename='fire_vulnerability_map', folder='ForestFireGoa'):
    """
    Export the fire vulnerability map to Google Drive.
    
    Args:
        vulnerability_map: ee.Image with fire vulnerability classification
        pa: ee.Geometry representing the study area
        filename: Output filename
        folder: Google Drive folder name
    """
    print(f"Exporting fire vulnerability map to Google Drive folder '{folder}'...")
    
    # Start the export task
    task = ee.batch.Export.image.toDrive({
        'image': vulnerability_map,
        'description': filename,
        'folder': folder,
        'fileNamePrefix': filename,
        'region': pa,
        'scale': 30,
        'maxPixels': 1e13
    })
    
    task.start()
    print(f"Export task started with ID: {task.id}")

# Function to export the vulnerability map to an Earth Engine asset
def export_vulnerability_map_to_asset(vulnerability_map, pa, asset_name):
    """
    Export the fire vulnerability map to an Earth Engine asset.
    
    Args:
        vulnerability_map: ee.Image with fire vulnerability classification
        pa: ee.Geometry representing the study area
        asset_name: Name of the Earth Engine asset
    """
    print(f"Exporting fire vulnerability map to Earth Engine asset: {asset_name}")
    
    # Start the export task
    task = ee.batch.Export.image.toAsset({
        'image': vulnerability_map,
        'description': asset_name.split('/')[-1],
        'assetId': asset_name,
        'region': pa,
        'scale': 30,
        'maxPixels': 1e13
    })
    
    task.start()
    print(f"Export task started with ID: {task.id}")

# Main function to run the fire vulnerability mapping workflow
def main():
    """
    Main function to run the fire vulnerability mapping workflow.
    """
    print("Starting fire vulnerability mapping for Goa, India...")
    
    # Get the study area boundary
    pa = get_study_boundary()
    
    # Load fire events data
    fire_all, fire_training, fire_validation = load_fire_events(pa)
    
    # Load roads data
    roads = load_roads(pa)
    
    # Load trend layers
    trend_layers = load_trend_layers(pa)
    
    # Generate random non-fire points
    non_fire_points = generate_non_fire_points(pa, fire_training, num_points=100)
    
    # Categorize fire risk based on temperature difference
    categorized_fire = categorize_fire_risk(fire_training, trend_layers, pa)
    
    # Prepare training data
    training_data = prepare_training_data(categorized_fire, non_fire_points, trend_layers, roads, pa)
    
    # Split into training and validation sets
    split = 0.8  # 80% for training, 20% for validation
    training_size = training_data.size().multiply(split).int()
    
    # Randomize the data
    randomized = training_data.randomColumn('random')
    
    # Split based on the random column
    train = randomized.filter(ee.Filter.lt('random', split))
    test = randomized.filter(ee.Filter.gte('random', split))
    
    # Train the Random Forest classifier
    classifier, predictor_names = train_random_forest(train)
    
    # Validate the model
    validation_metrics = validate_model(classifier, predictor_names, test)
    
    # Create a fire vulnerability map
    predictor_variables = trend_layers.addBands(roads.rename('road_distance'))
    vulnerability_map = create_vulnerability_map(classifier, predictor_variables, predictor_names, pa)
    
    # Export the vulnerability map to Google Drive (uncomment to use)
    # export_vulnerability_map(vulnerability_map, pa)
    
    # Export the vulnerability map to Earth Engine asset (uncomment to use)
    # user_asset_root = 'users/your_username/'  # Replace with your actual EE username
    # export_vulnerability_map_to_asset(
    #     vulnerability_map, 
    #     pa, 
    #     f"{user_asset_root}fire_vulnerability_map"
    # )
    
    print("Fire vulnerability mapping complete!")
    print("To visualize the results, check your Google Drive or Earth Engine assets.")

if __name__ == "__main__":
    main() 